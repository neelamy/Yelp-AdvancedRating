{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # function for splitting data to train and test sets\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rib amaze 2 hour wait time not so amaze but understandable.this place would get 5 star if they expand their bbq restaurant.their rib be amaze.you get so much food for the price and it taste sooo good.plus the two hour wait isnt always a bad thing because it give you an excuse to drink and gamble while you wait'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)|(=)\")\n",
    "\n",
    "def remove_punc(line):\n",
    "    review = REPLACE_NO_SPACE.sub(\"\", line.lower())\n",
    "    review = REPLACE_WITH_SPACE.sub(\" \", review)\n",
    "    return review\n",
    "\n",
    "def lemmatize(line):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    line = remove_punc(line)\n",
    "    return \" \".join([lemmatizer.lemmatize(word, pos='v') for word in nltk.word_tokenize(line)])\n",
    "\n",
    "\n",
    "def preprocess_review(review):\n",
    "    lines = [x for x in nltk.sent_tokenize(review) if len(x)>1]\n",
    "    return \". \".join([lemmatize(line) for line in lines])\n",
    "    \n",
    "    \n",
    "preprocess_review(\"Ribs = amazing\\n2 hour wait time= not so amazing, but understandable. \\n\\nThis place would get 5 stars if they expanded their BBQ restaurant. Their ribs are AMAZING. You get SO much food for the price and it tastes sooo good. Plus, the two hour wait isnt always a bad thing because it gives you an excuse to drink and gamble while you wait!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15231 40022\n"
     ]
    }
   ],
   "source": [
    "file = 'processed_reviews.json'\n",
    "with open(file,encoding=\"utf-8\") as f:\n",
    "    data = [next(f).strip() for x in range(100000)]\n",
    "\n",
    "positive=[]\n",
    "negative=[]\n",
    "\n",
    "test=[]\n",
    "   \n",
    "for x in data[300:]:\n",
    "    x = json.loads(x)\n",
    "    stars = x[\"stars\"]\n",
    "    if stars<2:\n",
    "        #negative.extend([y for y in x[\"text\"].split(\".\")])\n",
    "        negative.append(x[\"text\"])\n",
    "    if stars>4:\n",
    "        positive.append(x[\"text\"])\n",
    "        \n",
    "total = len(negative)+len(positive)\n",
    "print(len(negative),len(positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_data = []\n",
    "train_data.extend(positive[:12500])\n",
    "train_data.extend(negative[:12500])\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(train_data)\n",
    "X = cv.transform(train_data)\n",
    "X_test = cv.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.94736\n",
      "Accuracy for C=0.05: 0.95728\n",
      "Accuracy for C=0.25: 0.9584\n",
      "Accuracy for C=0.5: 0.95856\n",
      "Accuracy for C=1: 0.95904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = [5 if i < 12500 else 1 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for each sentence C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each sentence: 0.760425909494\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(X, target)\n",
    "\n",
    "x_input=[]\n",
    "x_val = []\n",
    "for x in data[:300]:\n",
    "    x = json.loads(x)\n",
    "    if x[\"stars\"] in [1,5]:\n",
    "        new_data = [y for y in x[\"text\"].split(\".\")]\n",
    "        x_input.extend(new_data)\n",
    "        x_val.extend([int(x[\"stars\"])]*len(new_data))\n",
    "\n",
    "X_test = cv.transform(x_input)\n",
    "print (\"Accuracy : %s\" \n",
    "       % ( accuracy_score(x_val, final_model.predict(X_test))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36939\n",
      "('delicious', 2.7752735465862237)\n",
      "('excellent', 2.384848753208368)\n",
      "('amaze', 2.345414104551343)\n",
      "('fantastic', 2.0501342303566248)\n",
      "('best', 2.0444112550176241)\n",
      "('great', 2.0015307342766238)\n",
      "('awesome', 1.9769120363137864)\n",
      "('perfect', 1.9321084525477419)\n",
      "('love', 1.5856131545219361)\n",
      "('wonderful', 1.4702294543982148)\n",
      "('worst', -3.2027793816067187)\n",
      "('horrible', -2.6572909207199409)\n",
      "('terrible', -2.6475747502441789)\n",
      "('awful', -2.2326144417316396)\n",
      "('mediocre', -2.2276312441795754)\n",
      "('overprice', -2.1890423835888493)\n",
      "('bland', -2.1294695601694147)\n",
      "('rude', -2.0507657285868768)\n",
      "('poor', -1.842755937210296)\n",
      "('disappointment', -1.7873470950430868)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "print(len(feature_to_coef))\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
